# --- WandB ---
wandb_project: spd-vision
wandb_run_name: null
wandb_run_name_prefix: ""

# --- General ---
seed: 0
C: 100
n_mask_samples: 1
n_ci_mlp_neurons: 0
target_module_patterns: ["vit.encoder.layer.*.attention.attention.*",
    "vit.encoder.layer.*.attention.output.dense",
    "vit.encoder.layer.*.intermediate.dense",
    "vit.encoder.layer.*.output.dense",
    #"classifier",
    ] # Everything?

# --- Loss Coefficients ---
faithfulness_coeff: 1
recon_coeff: null
stochastic_recon_coeff: 1
recon_layerwise_coeff: null
stochastic_recon_layerwise_coeff: null #1
importance_minimality_coeff: 1e-5
schatten_coeff: null
# embedding_recon_coeff: 1
embedding_recon_coeff: null
is_embed_unembed_recon: false
pnorm: 1.0
output_loss_type: mse
faithfulness_scale: null

# --- Training ---
batch_size: 64
steps: 5_000
lr: 1e-3
lr_schedule: constant
lr_warmup_pct: 0.01
lr_exponential_halflife: null
n_eval_steps: 100

# --- Logging & Saving ---
image_freq: 500
image_on_first_step: true
print_freq: 100
save_freq: null
log_ce_losses: true
log_accuracies: true

# --- Pretrained model info ---
pretrained_model_class: transformers.ViTForImageClassification
pretrained_model_name_hf: "google/vit-base-patch16-224"
pretrained_model_output_attr: logits
preprocessor_name: "google/vit-base-patch16-224"

# --- Task Specific ---
task_config:
  task_name: cv
  dataset_name: "Elriggs/imagenet-50-subset"
  train_data_split: "train"
  eval_data_split: "validation"
